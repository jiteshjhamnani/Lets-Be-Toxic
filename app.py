# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O6lRSxPvW5QpBhaGUvJcaPBZUd6ffpOT
"""

import streamlit as st
import joblib
import numpy as np
import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import nltk

# Setup
nltk.download('stopwords')
nltk.download('wordnet')

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

# Preprocessing function (same as in your model)
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    tokens = text.split()
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return ' '.join(tokens)

# Load model and vectorizer
model = joblib.load("model.pkl")
tfidf = joblib.load("tfidf.pkl")

label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']

# Streamlit UI
st.title("üí¨ Toxic Comment Classifier")
st.markdown("Enter a comment below and this app will predict whether it's toxic.")

text_input = st.text_area("üìù Enter your comment here:")

if st.button("Predict Toxicity"):
    if text_input.strip() == "":
        st.warning("Please enter some text.")
    else:
        clean_input = clean_text(text_input)
        transformed = tfidf.transform([clean_input])
        prediction = model.predict(transformed)

        st.subheader("üîç Prediction Results:")
        for label, result in zip(label_cols, prediction[0]):
            emoji = "‚úÖ" if result == 0 else "‚ö†Ô∏è"
            st.write(f"{label}: {result} {emoji}")